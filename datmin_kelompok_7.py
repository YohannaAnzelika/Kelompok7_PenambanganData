# -*- coding: utf-8 -*-
"""DATMIN_KELOMPOK 7

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fVi6eHgHlztC_OfX3ZUzbpQQVVe2yuId

**Mount Google Drive**
"""

from google.colab import drive
drive.mount('/content/drive')

zip_path = "/content/drive/MyDrive/Dataset Datmin/Dataset Tubes-20251127.zip"

"""**Ekstrak ZIP ke folder**"""

import zipfile
import os

extract_dir = "/content/dataset_tubes"
os.makedirs(extract_dir, exist_ok=True)

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_dir)

print(os.listdir(extract_dir))

"""**Load Dataset 1 & Dataset 2 secara terpisah**"""

import pandas as pd

# Dataset 1 (CSV)
dataset1_path = f"{extract_dir}/2021.csv"
dataset1 = pd.read_csv(dataset1_path)

# Dataset 2 (XLSX)
dataset2_path = f"{extract_dir}/Gelombang (1).xlsx"
dataset2 = pd.read_excel(dataset2_path)

dataset1.head(), dataset2.head()

"""**Import library**"""

import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectFromModel
from sklearn.decomposition import PCA
from sklearn.metrics import accuracy_score, classification_report

"""**Load Dataset 1 & Dataset 2**"""

extract_dir = "/content/dataset_tubes"

# Dataset 1: transaksi tahun 2021
dataset1_path = f"{extract_dir}/2021.csv"
dataset1 = pd.read_csv(dataset1_path)

print("Dataset 1 (2021.csv):")
print(dataset1.head())
print(dataset1.info())

# Dataset 2: gelombang
dataset2_path = f"{extract_dir}/Gelombang (1).xlsx"
dataset2 = pd.read_excel(dataset2_path, header=3)

print("\nDataset 2 (Gelombang (1).xlsx):")
print(dataset2.head())
print(dataset2.info())

"""**Preprocessing Dataset 1 â€” Target = Jenis Transaksi (Masuk vs Keluar)**"""

df1 = dataset1.copy()

# Asumsi: transaksi masuk punya QTY_MSK > 0, transaksi keluar punya QTY_KLR > 0
# Kita definisikan: 1 = Masuk, 0 = Keluar
df1['TIPE_TRANSAKSI'] = np.where(df1['QTY_MSK'] > 0, 1, 0)

print(df1[['QTY_MSK', 'QTY_KLR', 'TIPE_TRANSAKSI']].head())
print(df1['TIPE_TRANSAKSI'].value_counts())

"""**Preprocessing Dataset 2: Gelombang**"""

# === LOAD DATASET GELOMBANG DENGAN HEADER BARIS KE-4 ===
dataset2_path = f"{extract_dir}/Gelombang (1).xlsx"

df2 = pd.read_excel(dataset2_path, header=4)
print("Kolom df2:", df2.columns)
print(df2.head())

# === TEMUKAN KOLOM HSIG ===
hsig_col = [c for c in df2.columns if "hsig" in c.lower()][0]
print("Kolom Hsig:", hsig_col)

# === BERSIHKAN BARIS KOSONG ===
df2 = df2.dropna(subset=[hsig_col])
df2[hsig_col] = pd.to_numeric(df2[hsig_col], errors='coerce')
df2 = df2.dropna(subset=[hsig_col])

# === HITUNG MEDIAN GT DAN BUAT KELAS GELOMBANG ===
median_hsig = df2[hsig_col].median()
print("Median Hsig:", median_hsig)

df2['WAVE_CLASS'] = np.where(df2[hsig_col] > median_hsig, 1, 0)
print(df2[[hsig_col, 'WAVE_CLASS']].head())
print(df2['WAVE_CLASS'].value_counts())

"""**Eksekusi Model & Hasil**"""

def run_experiments(df, target, nama):
    print("\n", nama, "\n")

    # Fitur & label
    X = df.drop(columns=[target])
    y = df[target]

    # Deteksi tipe kolom
    cat_cols = X.select_dtypes(include=['object','category']).columns
    num_cols = X.select_dtypes(include=['int64','float64']).columns

    print("Kategorikal :", list(cat_cols))
    print("Numerik     :", list(num_cols))

    # Preprocessing (encode + scale)
    prep = ColumnTransformer([
        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols),
        ('num', StandardScaler(), num_cols)
    ])

    # Split data
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, stratify=y, random_state=42
    )

    # 1. BASELINE
    model_base = Pipeline([
        ('prep', prep),
        ('tree', DecisionTreeClassifier(random_state=42))
    ])
    model_base.fit(X_train, y_train)
    pred_base = model_base.predict(X_test)

    print("\n[BASELINE]")
    print("Accuracy :", accuracy_score(y_test, pred_base))
    print(classification_report(y_test, pred_base))

    # 2. FEATURE SELECTION
    model_fs = Pipeline([
        ('prep', prep),
        ('fs', SelectFromModel(RandomForestClassifier(
            n_estimators=200, random_state=42, n_jobs=-1
        ))),
        ('tree', DecisionTreeClassifier(random_state=42))
    ])
    model_fs.fit(X_train, y_train)
    pred_fs = model_fs.predict(X_test)

    print("\n[FEATURE SELECTION]")
    print("Accuracy :", accuracy_score(y_test, pred_fs))
    print(classification_report(y_test, pred_fs))

    # 3. PCA ONLY
    model_pca = Pipeline([
        ('prep', prep),
        ('pca', PCA(n_components=5)),
        ('tree', DecisionTreeClassifier(random_state=42))
    ])
    model_pca.fit(X_train, y_train)
    pred_pca = model_pca.predict(X_test)

    print("\n[PCA ONLY]")
    print("Accuracy :", accuracy_score(y_test, pred_pca))
    print(classification_report(y_test, pred_pca))

    # 4. FEATURE SELECTION + PCA
    model_fspca = Pipeline([
        ('prep', prep),
        ('fs', SelectFromModel(RandomForestClassifier(
            n_estimators=200, random_state=42, n_jobs=-1
        ))),
        ('pca', PCA(n_components=5)),
        ('tree', DecisionTreeClassifier(random_state=42))
    ])
    model_fspca.fit(X_train, y_train)
    pred_fspca = model_fspca.predict(X_test)

    print("\n[FS + PCA]")
    print("Accuracy :", accuracy_score(y_test, pred_fspca))
    print(classification_report(y_test, pred_fspca))

    # Hasil untuk tabel evaluasi
    return {
        "baseline": accuracy_score(y_test, pred_base),
        "fs": accuracy_score(y_test, pred_fs),
        "pca": accuracy_score(y_test, pred_pca),
        "fspca": accuracy_score(y_test, pred_fspca)
    }

hasil1 = run_experiments(df1, 'TIPE_TRANSAKSI', 'Dataset 1 - Transaksi 2021')
hasil1

hasil2 = run_experiments(df2, 'WAVE_CLASS', 'Dataset 2 - Gelombang Laut')
hasil2

import pandas as pd

eval_df = pd.DataFrame({
    "Metode": ["Baseline", "Feature Selection", "PCA Only", "FS + PCA"],
    "Dataset 1 Accuracy": [
        hasil1["baseline"],
        hasil1["fs"],
        hasil1["pca"],
        hasil1["fspca"]
    ],
    "Dataset 2 Accuracy": [
        hasil2["baseline"],
        hasil2["fs"],
        hasil2["pca"],
        hasil2["fspca"]
    ]
})

print("\nTabel Evaluasi Sebelum vs Sesudah Preprocessing (Metode Jurnal)\n")
print(eval_df.to_string(index=False))